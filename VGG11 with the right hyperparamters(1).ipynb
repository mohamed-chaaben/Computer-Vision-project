{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b26eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/anaconda3/envs/mohamed-chaaben/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/bin/anaconda3/envs/mohamed-chaaben/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZNK3c107SymBool10guard_boolEPKcl'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import vgg11\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f795b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/mohamed_chaaben/Documents/Colorectal Cancer /\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95ca4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5bc73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg11(num_classes=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c18b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate(batch_size, learning_rate):\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 5\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f'Validation Loss: {val_loss}')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "\n",
    "        if no_improvement_count >= patience:\n",
    "            print(f'Early stopping after {epoch + 1} epochs with no improvement.')\n",
    "            break\n",
    "\n",
    "    print('Training finished.')\n",
    "    print('Testing begin.')\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    all_labels = []\n",
    "    all_predicted = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "      \n",
    "            all_predicted.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    precision = precision_score(all_labels, all_predicted, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predicted, average='weighted')\n",
    "    \n",
    "    \n",
    "\n",
    "    print(f'Test Accuracy: {accuracy}%')\n",
    "    print(f'Test Loss: {avg_test_loss}')\n",
    "    print('Test Precision', precision)\n",
    "    print('Test recall', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5727a437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 1.0221368046601613\n",
      "Validation Loss: 0.8406966328620911\n",
      "Epoch 2/50 - Loss: 0.754849937359492\n",
      "Validation Loss: 0.5679091215133667\n",
      "Epoch 3/50 - Loss: 0.6077094628413519\n",
      "Validation Loss: 0.7902147769927979\n",
      "Epoch 4/50 - Loss: 0.5652298400799434\n",
      "Validation Loss: 0.5032984018325806\n",
      "Epoch 5/50 - Loss: 0.5349207387367885\n",
      "Validation Loss: 0.5249870419502258\n",
      "Epoch 6/50 - Loss: 0.47042875200510026\n",
      "Validation Loss: 0.41092532873153687\n",
      "Epoch 7/50 - Loss: 0.4239175945520401\n",
      "Validation Loss: 0.4393293261528015\n",
      "Epoch 8/50 - Loss: 0.4433361538251241\n",
      "Validation Loss: 0.3195028007030487\n",
      "Epoch 9/50 - Loss: 0.38246393789847694\n",
      "Validation Loss: 0.3776428699493408\n",
      "Epoch 10/50 - Loss: 0.338593795945247\n",
      "Validation Loss: 0.17764754593372345\n",
      "Epoch 11/50 - Loss: 0.33336414421598115\n",
      "Validation Loss: 0.3130112588405609\n",
      "Epoch 12/50 - Loss: 0.3276830571889877\n",
      "Validation Loss: 0.4190292954444885\n",
      "Epoch 13/50 - Loss: 0.3086800976097584\n",
      "Validation Loss: 0.22001232206821442\n",
      "Epoch 14/50 - Loss: 0.2616087478895982\n",
      "Validation Loss: 0.22712770104408264\n",
      "Epoch 15/50 - Loss: 0.26051047692696255\n",
      "Validation Loss: 0.17581793665885925\n",
      "Epoch 16/50 - Loss: 0.2353806872665882\n",
      "Validation Loss: 0.11402248591184616\n",
      "Epoch 17/50 - Loss: 0.21567194923758506\n",
      "Validation Loss: 0.35504648089408875\n",
      "Epoch 18/50 - Loss: 0.22135498161117237\n",
      "Validation Loss: 0.2161453664302826\n",
      "Epoch 19/50 - Loss: 0.18773042286435762\n",
      "Validation Loss: 0.13394217193126678\n",
      "Epoch 20/50 - Loss: 0.1693428426856796\n",
      "Validation Loss: 0.13926996290683746\n",
      "Epoch 21/50 - Loss: 0.17754415034006038\n",
      "Validation Loss: 0.11184660345315933\n",
      "Epoch 22/50 - Loss: 0.17056343026459217\n",
      "Validation Loss: 0.0736292153596878\n",
      "Epoch 23/50 - Loss: 0.1529343011478583\n",
      "Validation Loss: 0.1233334168791771\n",
      "Epoch 24/50 - Loss: 0.2163725508004427\n",
      "Validation Loss: 0.1235048696398735\n",
      "Epoch 25/50 - Loss: 0.13563184040288132\n",
      "Validation Loss: 0.12314223498106003\n",
      "Epoch 26/50 - Loss: 0.14281183760613203\n",
      "Validation Loss: 0.18530921638011932\n",
      "Epoch 27/50 - Loss: 0.14366563059389592\n",
      "Validation Loss: 0.17146573960781097\n",
      "Early stopping after 27 epochs with no improvement.\n",
      "Training finished.\n",
      "Testing begin.\n",
      "Test Accuracy: 93.16666666666667%\n",
      "Test Loss: 0.17537438212648818\n",
      "Test Precision 0.933826861796294\n",
      "Test recall 0.9316666666666666\n"
     ]
    }
   ],
   "source": [
    "train_validate(32, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c811716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  torch.save(model, \"Best hyperparameters model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b9494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
